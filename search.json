[{"path":[]},{"path":"/CODE_OF_CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported community leaders responsible enforcement [INSERT CONTACT METHOD]. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"/CODE_OF_CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/ code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https:// www.contributor-covenant.org/translations.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Robert Allaway Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/annotate-nf-processed-data.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"Annotating nextflow processed data","text":"vignette documents -practice usage annotation utils nf-processed data files; probably updated practices underlying functions refined. copy paste code try , need least read access. code modify entities’ provenance/annotations evaluated.","code":""},{"path":"/articles/annotate-nf-processed-data.html","id":"important-note","dir":"Articles","previous_headings":"","what":"Important note","title":"Annotating nextflow processed data","text":"may notice one minor difference annotation utils RNA-seq expression vs variant calling data. main difference one add workflow directly, doesn’t. design change made consistent across annotation functions going forward, workflow values added everything default, functions kept date make consistency easy DCC staff. non-nf-processed data, values can still overridden.","code":""},{"path":"/articles/annotate-nf-processed-data.html","id":"set-up","dir":"Articles","previous_headings":"","what":"Set up","title":"Annotating nextflow processed data","text":"First load nfportalutils package log . recommended default usage syn_login use without directly passing credentials. Instead, available SYNAPSE_AUTH_TOKEN environment variable token stored therein.","code":"library(nfportalutils) library(data.table) syn_login()"},{"path":[]},{"path":"/articles/annotate-nf-processed-data.html","id":"creating-helper-resource-files","dir":"Articles","previous_headings":"nf-rnaseq","what":"Creating helper resource files","title":"Annotating nextflow processed data","text":"add annotations provenance, need reference mapping inputs outputs involved workflow. puts together table representing mapping parsing samplesheet combination output directory (“star_salmon”). nextflow rna-seq workflow, samplesheet output file “pipeline_info”.","code":"sample_io <- map_sample_io(workflow = \"nf-rnaseq\",                            samplesheet = \"syn30841441\", # synapse file                            syn_out = \"syn30840584\")"},{"path":"/articles/annotate-nf-processed-data.html","id":"add-provenance","dir":"Articles","previous_headings":"nf-rnaseq","what":"Add provenance","title":"Annotating nextflow processed data","text":"Add provenance files involved using add_activity_batch. Note: workflow name already available workflow link? workflow link specific reference includes version numbers.","code":"wf_link <- \"https://nf-co.re/rnaseq/3.7/output#star-and-salmon\" prov <- add_activity_batch(sample_io$output_id,                             sample_io$workflow,                             wf_link,                            sample_io$input_id)"},{"path":"/articles/annotate-nf-processed-data.html","id":"add-annotations","dir":"Articles","previous_headings":"nf-rnaseq","what":"Add annotations","title":"Annotating nextflow processed data","text":"Annotations expected aligned reads output different quantified expression output. handled couple specialized functions.","code":""},{"path":"/articles/annotate-nf-processed-data.html","id":"aligned-reads-data-files","dir":"Articles","previous_headings":"nf-rnaseq > Add annotations","what":"Aligned reads data files","title":"Annotating nextflow processed data","text":"First, helps see template aligned reads(.bam) data. looks like large number different annotations put together (though optional). Fortunately, utility annotate_aligned_reads try much work. look .bam files generate annotations .bam files. template schema mentioned defaults don’t specified explicitly. ’s recommended read docs (?annotate_aligned_reads) details annotations compiled; usage annotate_aligned_reads still require knowing filled manually. Note: workflow info added provenance annotations? Isn’t redundant? answer portal uses annotations provenance/annotations queryable currently. looks good, can go ahead apply annotations: : Instead submitting , prefer submit via schematic/DCA, can make schematic-compatible manifest.","code":"template <- \"bts:ProcessedAlignedReadsTemplate\" schema <- \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\" props <- get_dependency_from_json_schema(id = template) props l2_manifest <- annotate_aligned_reads(sample_io,                                       samtools_stats_file = \"syn30841284\",                                       update = FALSE)  l2_manifest[, genomicReference := \"GRCh38\"] l2_manifest[, workflowLink := \"https://nf-co.re/rnaseq/3.7/output#star-and-salmon\"] annotate_with_manifest(l2_manifest)"},{"path":"/articles/annotate-nf-processed-data.html","id":"expression-data-files","dir":"Articles","previous_headings":"nf-rnaseq > Add annotations","what":"Expression data files","title":"Annotating nextflow processed data","text":"Another convenience function provided help annotate gene expression data files.","code":"l3_manifest <- annotate_expression(sample_io, update = FALSE) l3_manifest[, workflowLink := \"https://nf-co.re/rnaseq/3.7/output#star-and-salmon\"] annotate_with_manifest(l3_manifest)"},{"path":"/articles/annotate-nf-processed-data.html","id":"nf-sarek","dir":"Articles","previous_headings":"","what":"nf-sarek","title":"Annotating nextflow processed data","text":"second part vignette show, process variant data much different, though mapping inputs-outputs can somewhat slower.","code":""},{"path":"/articles/annotate-nf-processed-data.html","id":"creating-helper-resource-files-1","dir":"Articles","previous_headings":"nf-sarek","what":"Creating helper resource files","title":"Annotating nextflow processed data","text":"","code":"sample_io <- map_sample_io(workflow = \"nf-sarek\",                            samplesheet = \"PilotBatch-WES-samplesheet.txt\", # local file                            syn_out = \"syn27650634\") # Modify workflow assignment a bit sample_io[workflow ==\"Strelka\", workflow := \"Strelka2\"]"},{"path":"/articles/annotate-nf-processed-data.html","id":"add-provenance-1","dir":"Articles","previous_headings":"nf-sarek","what":"Add provenance","title":"Annotating nextflow processed data","text":"Use manifest add provenance.","code":"wf_link <- c(FreeBayes = \"https://nf-co.re/sarek/2.7.1/output#freebayes\",              Mutect2 = \"https://nf-co.re/sarek/2.7.1/output#gatk-mutect2\",              Strelka2 = \"https://nf-co.re/sarek/2.7.1/output#strelka2\") add_activity_batch(sample_io$output_id,                     sample_io$workflow,                     wf_link[sample_io$workflow],                     sample_io$input_id)"},{"path":"/articles/annotate-nf-processed-data.html","id":"add-annotations-1","dir":"Articles","previous_headings":"nf-sarek","what":"Add annotations","title":"Annotating nextflow processed data","text":"annotate_called_variants util used somatic germline results, automatically try fill right values. However, can set parameters directly – see ?annotate_called_variants. returns manifest examination correction needed. example, used slightly different version/fork, update manually manifest. Otherwise, apply annotations:","code":"manifest <- annotate_called_variants(sample_io) annotate_with_manifest(manifest)"},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"special-acknowledgments","dir":"Articles","previous_headings":"","what":"Special acknowledgments","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"Functionality demonstrated vignette benefited greatly code originally written hhunterzinck.","code":""},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"briefly describes usage bringing data NF-OSI (mainly NF-OSI processed data) brought platforms (mainly cBioPortal).","code":""},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"set-up","dir":"Articles","previous_headings":"","what":"Set up","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"First load nfportalutils package log . recommended default usage syn_login use without directly passing credentials. Instead, available SYNAPSE_AUTH_TOKEN environment variable token stored therein.","code":"library(nfportalutils) syn_login()"},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"creating-a-mutations-dataset","dir":"Articles","previous_headings":"","what":"Creating a mutations dataset","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"Compilation cBioPortal dataset require putting together number assets Synapse elsewhere, package make seem straightforward possible. merged_maf references final output file NF-OSI processing pipeline directly ready public release. modifications needed file (except renaming ). ref_view fileview contains annotations files released. samplesheet samplesheet used data processing ultimately creating merged_maf ref_map maps clinical variables NF-OSI data dictionary cBioPortal’s create folder set files needed.","code":"merged_maf <- \"syn36553188\" ref_view <- \"syn43278088\" samplesheet <- \"syn41830510\" ref_map <- \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/mappings/cBioPortal.yaml\" syncBP_maf(merged_maf,            samplesheet,            ref_map,            ref_view,            cancer_study_identifier = \"mixed_nfosi_2022\",            name = \"Plexiform Neurofibroma and Neurofibroma (Pratilas 2022)\",            citation = \"TBD\")"},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"updating-or-adding-to-a-dataset","dir":"Articles","previous_headings":"","what":"Updating or adding to a dataset","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"-section.","code":""},{"path":"/articles/bringing-portal-data-to-other-platforms-cbioportal.html","id":"validation","dir":"Articles","previous_headings":"","what":"Validation","title":"Bringing Portal Data to Other Platforms (cBioPortal)","text":"additional steps generating case lists validation done outside package cBioPortal backend, portal may specific configurations (genomic reference) validate . See general docs dataset validation. public portal, suggested step using public server given . Assuming present working directory ~/datahub/public study folder called mixed_nfosi_2022 placed , mount dataset container run validation like : docker run --rm -v $(pwd):/datahub cbioportal/cbioportal:4.1.13 validateStudies.py -d /datahub -l mixed_nfosi_2022 -u http://cbioportal.org -html /datahub/mixed_nfosi_2022/html_report","code":""},{"path":"/articles/survey-public-files.html","id":"intro","dir":"Articles","previous_headings":"","what":"Intro","title":"Surveying public files in the portal","text":"quick makes use functions survey files portal access.","code":""},{"path":"/articles/survey-public-files.html","id":"set-up","dir":"Articles","previous_headings":"","what":"Set up","title":"Surveying public files in the portal","text":"usual setup:","code":"library(nfportalutils) syn_login()"},{"path":"/articles/survey-public-files.html","id":"files-downloadable-for-synapse-registered-users","dir":"Articles","previous_headings":"","what":"Files downloadable for Synapse registered users","title":"Surveying public files in the portal","text":"talking “public” files, usually means files viewable downloadable Synapse users. group id 273948, use query : Breakdown absolute number proportions:","code":"public_access <- summarize_file_access(principal_id = 273948, \"DOWNLOAD\", \"syn16858331\") public_access public_access[, .(n_files = sum(N)), by = access][, .(access, n_files, proportion = n_files / sum(n_files))]"},{"path":"/articles/survey-public-files.html","id":"some-nuances","dir":"Articles","previous_headings":"","what":"Some Nuances","title":"Surveying public files in the portal","text":"nice see file access restrictions different points time, note underlying API returns access control info present. file may inherited benefactor earlier point, becomes benefactor later (.e. granular access control), queries based past state likely work. Don’t try something like:","code":"public_access_q3_2022 <- summarize_file_access(principal_id = 273948, \"DOWNLOAD\", \"syn16858331.47\")"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert Allaway. Author, maintainer. Anh Nguyet Vu. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Allaway R, Vu (2023). nfportalutils: NF Portal Utilities. R package version 0.0.0.9110, https://github.com/nf-osi/nfportalutils.","code":"@Manual{,   title = {nfportalutils: NF Portal Utilities},   author = {Robert Allaway and Anh Nguyet Vu},   year = {2023},   note = {R package version 0.0.0.9110},   url = {https://github.com/nf-osi/nfportalutils}, }"},{"path":"/index.html","id":"nfportalutils","dir":"","previous_headings":"","what":"NF Portal Utilities","title":"NF Portal Utilities","text":"goal nfportalutils provide convenience functions project (meta)data management NF-OSI data portal scope. Currently, develop branch default package install docs refer code branch.","code":""},{"path":"/index.html","id":"docs","dir":"","previous_headings":"","what":"Docs","title":"NF Portal Utilities","text":"👉 Package documentation!","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"NF Portal Utilities","text":"can install nfportalutils :","code":"remotes::install_github(\"nf-osi/nfportalutils\")"},{"path":"/index.html","id":"other-package-notes","dir":"","previous_headings":"","what":"Other Package Notes","title":"NF Portal Utilities","text":"couple vignettes available precomputed. vignette downloaded, use e.g. vignette(\"annotate-nf-processed-data\", package = \"nfportalutils\") view. development, run devtools::check(vignettes = FALSE) early often. minimal, address ERRORS WARNINGS. Yes, lot NOTES need resolved.","code":""},{"path":"/index.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"NF Portal Utilities","text":"Please note nfportalutils project released Contributor Code Conduct. contributing project, agree abide terms.","code":""},{"path":"/reference/add_activity.html","id":null,"dir":"Reference","previous_headings":"","what":"Add activity to entity — add_activity","title":"Add activity to entity — add_activity","text":"Util adding activity info file entity. See also https://help.synapse.org/docs/Provenance.1972470373.html","code":""},{"path":"/reference/add_activity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add activity to entity — add_activity","text":"","code":"add_activity(entity, act_name, act_executed, used_inputs)"},{"path":"/reference/add_activity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add activity to entity — add_activity","text":"entity Synapse entity id. act_name Name activity. act_executed Reference activity executed (URL preferred). used_inputs Vector inputs act, e.g. syn ids, links data sources, etc.","code":""},{"path":"/reference/add_activity_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Add activity to multiple entities — add_activity_batch","title":"Add activity to multiple entities — add_activity_batch","text":"Wrapper provenance function little work expand many--many mappings create records entity, activity, input.","code":""},{"path":"/reference/add_activity_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add activity to multiple entities — add_activity_batch","text":"","code":"add_activity_batch(entities, act_name, act_executed, used_inputs)"},{"path":"/reference/add_activity_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add activity to multiple entities — add_activity_batch","text":"entities Vector list entities. act_name Vector list activity name. act_executed Vector list reference activity executed. used_inputs Vector list inputs entity.","code":""},{"path":"/reference/add_default_fileview.html","id":null,"dir":"Reference","previous_headings":"","what":"Create default project fileview — add_default_fileview","title":"Create default project fileview — add_default_fileview","text":"Create default project fileview","code":""},{"path":"/reference/add_default_fileview.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create default project fileview — add_default_fileview","text":"","code":"add_default_fileview(project)"},{"path":"/reference/add_default_fileview.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create default project fileview — add_default_fileview","text":"project project entity.","code":""},{"path":"/reference/add_default_folders.html","id":null,"dir":"Reference","previous_headings":"","what":"Create default folders — add_default_folders","title":"Create default folders — add_default_folders","text":"convenience wrapper around make_folder NF defaults.","code":""},{"path":"/reference/add_default_folders.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create default folders — add_default_folders","text":"","code":"add_default_folders(   project,   folders = c(\"Analysis\", \"Milestone Reports\", \"Raw Data\") )"},{"path":"/reference/add_default_folders.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create default folders — add_default_folders","text":"project project Synapse id object. folders Names standard set folders.","code":""},{"path":"/reference/add_default_wiki.html","id":null,"dir":"Reference","previous_headings":"","what":"Add default wiki — add_default_wiki","title":"Add default wiki — add_default_wiki","text":"Add default wiki project creation use retrofit projects creators created wiki.","code":""},{"path":"/reference/add_default_wiki.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add default wiki — add_default_wiki","text":"","code":"add_default_wiki(   project,   name,   pi,   lead,   funder,   initiative,   abstract,   institution )"},{"path":"/reference/add_default_wiki.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add default wiki — add_default_wiki","text":"project Synapse id project. name Name project/study. pi Name principal investigator. lead Name(s) project lead/data coordinator, comma-sep multiple, e.g. \"Jane Doe, John Doe\". funder funding agency. relevant funder team made admin. initiative Title funding initiative, e.g. \"Young Investigator Award\". abstract Project abstract/description. institution Affiliated institution(s), semicolon-sep multiple, e.g. \"Stanford University; University California, San Francisco\".","code":""},{"path":"/reference/add_people_from_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the People table from a source Table or View column — add_people_from_table","title":"Update the People table from a source Table or View column — add_people_from_table","text":"Update People table source Table View column","code":""},{"path":"/reference/add_people_from_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the People table from a source Table or View column — add_people_from_table","text":"","code":"add_people_from_table(   people_table_id,   people_column,   source_table_id,   source_column,   dry_run = T )"},{"path":"/reference/add_people_from_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the People table from a source Table or View column — add_people_from_table","text":"people_table_id synapse id table used referencing people. people_column Column name within people table contains relevant people values. source_table_id synapse id source table. source_column Column name within source table contains relevant source values. dry_run Default = TRUE Skips upload annotations unless set FALSE.","code":""},{"path":"/reference/add_people_from_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update the People table from a source Table or View column — add_people_from_table","text":"dry_run == T, prints preview updated people table, otherwise uploads updates.","code":""},{"path":"/reference/add_publication_from_pubmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a publication to the publication table — add_publication_from_pubmed","title":"Add a publication to the publication table — add_publication_from_pubmed","text":"Requires publication PubMed auto-derive metadata authors, title, etc. contrast, disease_focus manifestation need supplemented curator. study_id used get consistent studyName fundingAgency study table without manual input.","code":""},{"path":"/reference/add_publication_from_pubmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a publication to the publication table — add_publication_from_pubmed","text":"","code":"add_publication_from_pubmed(   pmid,   study_id,   disease_focus,   manifestation,   publication_table_id,   study_table_id,   dry_run = T )"},{"path":"/reference/add_publication_from_pubmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a publication to the publication table — add_publication_from_pubmed","text":"pmid PubMed ID (PMCID) publication added. study_id Synapse id(s) study associated publication. disease_focus disease focus(s) associated publication. manifestation manifestation(s) associated publication. publication_table_id Synapse id portal publication table. Must write access. study_table_id Synapse id portal study table. Need read access. dry_run Default = TRUE. Skips upload table instead prints formatted publication metadata.","code":""},{"path":"/reference/add_publication_from_pubmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a publication to the publication table — add_publication_from_pubmed","text":"dry_run == T, returns publication metadata added.","code":""},{"path":"/reference/add_publication_from_pubmed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a publication to the publication table — add_publication_from_pubmed","text":"","code":"if (FALSE) { add_publication_from_pubmed(                pmid = \"33574490\",                study_id = \"syn2343195\",                disease_focus = c(\"Neurofibromatosis\"),                manifestation = c(\"Meningioma\"),                publication_table_id = \"syn16857542\",                study_table_id = \"syn16787123\") }"},{"path":"/reference/add_publication_from_unpaywall.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","title":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","text":"Add publication publication table. Publication must unpaywall database retrieve info. parameter-provided metadata (e.g. \"studyName\"), function must JSON-formatted character vector destination Synapse column \"STRING_LIST\" format. Currently, function evaluate schema, must checked manually.","code":""},{"path":"/reference/add_publication_from_unpaywall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","text":"","code":"add_publication_from_unpaywall(   publication_table_id,   email_address,   doi,   is_preprint = F,   preprint_server = NULL,   study_name,   study_id,   funding_agency,   disease_focus,   manifestation,   dry_run = T )"},{"path":"/reference/add_publication_from_unpaywall.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","text":"publication_table_id synapse id portal publication table. Must write access. email_address valid email address. used request metadata Unpaywall API. Please change example real email address help Unpaywall accurately track usage. doi DOI preprint added. is_preprint Default = FALSE. Set TRUE DOI preprint. preprint_server Provide preprint server name. Must one 'bioRxiv', 'medRxiv', 'chemRxiv', 'arXiv' study_name name(s) study associated publication. study_id synapse id(s) study associated publication. funding_agency funding agency(s) associated publication. disease_focus disease focus(s) associated publication. manifestation manifestation(s) associated publication. dry_run Default = TRUE. Skips upload table instead prints formatted publication metadata.","code":""},{"path":"/reference/add_publication_from_unpaywall.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","text":"dry_run == T, returns publication metadata added.","code":""},{"path":"/reference/add_publication_from_unpaywall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add a publication or preprint to the publication table via the Unpaywall API. — add_publication_from_unpaywall","text":"","code":"if (FALSE) { add_publication_from_unpaywall(publication_table_id = 'syn16857542',                email_address = 'foo@bar.com',                doi = '10.1074/jbc.RA120.014960',                study_name = c(toJSON(\"Synodos NF2\")),                study_id = c(toJSON(\"syn2343195\")),                funding_agency = c(toJSON(\"CTF\")),                disease_focus = \"Neurofibromatosis 2\",                manifestation = c(toJSON(\"Meningioma\")),                dry_run = T) }"},{"path":"/reference/add_publications_from_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Add a batch of publications from spreadsheet — add_publications_from_file","title":"Add a batch of publications from spreadsheet — add_publications_from_file","text":"Add batch publications spreadsheet","code":""},{"path":"/reference/add_publications_from_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add a batch of publications from spreadsheet — add_publications_from_file","text":"","code":"add_publications_from_file(   file,   publication_table_id,   study_table_id,   list_sep = \"|\",   dry_run = TRUE )"},{"path":"/reference/add_publications_from_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add a batch of publications from spreadsheet — add_publications_from_file","text":"file Spreadsheet (.csv/.tsv) pubs add pmid, studyId, diseaseFocus, manifestation. pmid one per row unique, rest can list_sep vals. publication_table_id Synapse id portal publication table. Must write access. study_table_id Synapse id portal study table. Need read access. list_sep Delimiter character used separate list columns. dry_run Default = TRUE. Skips upload table instead prints formatted publication metadata.","code":""},{"path":"/reference/annotate_aligned_reads.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotate processed aligned reads — annotate_aligned_reads","title":"Annotate processed aligned reads — annotate_aligned_reads","text":"Put together annotation components nextflow star-salmon outputs. Annotations come several sources: Inherit annotations original input files. Requires reference mapping input files use. prop vals can inherited derived files, e.g. assay type, \"comments\" \"entityId\". Ideally, data model include inheritance rules; since possible currently, hard-code lots stuff, hard generalize data models.","code":""},{"path":"/reference/annotate_aligned_reads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotate processed aligned reads — annotate_aligned_reads","text":"","code":"annotate_aligned_reads(   sample_io,   samtools_stats_file = NULL,   picard_stats_file = NULL,   template = \"bts:ProcessedAlignedReadsTemplate\",   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   verbose = TRUE,   dry_run = TRUE )"},{"path":"/reference/annotate_aligned_reads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annotate processed aligned reads — annotate_aligned_reads","text":"sample_io Table mapping input outputs. samtools_stats_file Path file/syn id file samtools stats produced workflow. picard_stats_file Path file/syn id file picard stats produced workflow. template (Optional) URI template data model use, prefixed needed. Can specify different model/version, cases may work well. schema Path (URL local) file schema read, schema list object. verbose Give verbose reports happening. dry_run Whether apply annotations.","code":""},{"path":"/reference/annotate_aligned_reads.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Annotate processed aligned reads — annotate_aligned_reads","text":"Extract metrics auxiliary files surface annotations. See annotate_with_tool_stats. Manually add annotations (yet?) derived #1 #2. done outside util. Always returns \"partial\" manifest, can adjusted needed; example, default values linked workflow version date. param dry_run specifies whether annotations applied.","code":""},{"path":"/reference/annotate_called_variants.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotate somatic or germline variants output — annotate_called_variants","title":"Annotate somatic or germline variants output — annotate_called_variants","text":"Currently, vcf output first mafs appear subsequent workflow run, depending map_sample_output_sarek run create sample_io file, just vcf files . (future, workflows likely joined deposited run.) One can specify annotate either \"vcf\" \"maf\" files create manifest just files, use \"auto\" detect file types present sample_io.","code":""},{"path":"/reference/annotate_called_variants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotate somatic or germline variants output — annotate_called_variants","text":"","code":"annotate_called_variants(   sample_io,   format = c(\"auto\", \"vcf\", \"maf\"),   template = \"bts:ProcessedVariantCallsTemplate\",   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   data_type = c(\"auto\", \"SomaticVariants\", \"GermlineVariants\",     \"AnnotatedSomaticVariants\", \"AnnotatedGermlineVariants\"),   verbose = TRUE,   dry_run = TRUE )"},{"path":"/reference/annotate_called_variants.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annotate somatic or germline variants output — annotate_called_variants","text":"sample_io Table mapping input outputs, reference output .vcf.gz maf files. format Variant format, \"auto\" handle \"vcf\" \"maf\" files present automatically, specify one explicitly. See details. template (Optional) URI template data model use, prefixed needed. Can specify different model/version, cases may work well. schema Path (URL local) file schema read, schema list object. data_type Variant type, use \"auto\" infer naming scheme current NF processing SOP, specify explicitly. verbose Give verbose reports happening. dry_run Whether apply annotations.","code":""},{"path":"/reference/annotate_called_variants.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Annotate somatic or germline variants output — annotate_called_variants","text":"maf files use template different default values, subclass term dataType. future mafs require significantly different template, factored separate annotation function.","code":""},{"path":"/reference/annotate_expression.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotate processed expression output — annotate_expression","title":"Annotate processed expression output — annotate_expression","text":"Annotate processed expression output","code":""},{"path":"/reference/annotate_expression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotate processed expression output — annotate_expression","text":"","code":"annotate_expression(   sample_io,   template = \"bts:ProcessedExpressionTemplate\",   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   verbose = TRUE,   dry_run = TRUE )"},{"path":"/reference/annotate_expression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annotate processed expression output — annotate_expression","text":"sample_io Table mapping input outputs, outputs expected .sf files. template (Optional) URI template data model use, prefixed needed. Can specify different model/version, cases may work well. schema Path (URL local) file schema read, schema list object. verbose Give verbose reports happening. dry_run Whether apply annotations.","code":""},{"path":"/reference/annotate_reports_sarek.html","id":null,"dir":"Reference","previous_headings":"","what":"Annotate Sarek reports — annotate_reports_sarek","title":"Annotate Sarek reports — annotate_reports_sarek","text":"First runs map_reports_sarek hood.","code":""},{"path":"/reference/annotate_reports_sarek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Annotate Sarek reports — annotate_reports_sarek","text":"","code":"annotate_reports_sarek(syn_out, project, dry_run)"},{"path":"/reference/annotate_reports_sarek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Annotate Sarek reports — annotate_reports_sarek","text":"syn_out Reports output folder set scope fileview. project Project put fileview. dry_run Whether submit annotations just return manifest.","code":""},{"path":"/reference/annotate_with_manifest.html","id":null,"dir":"Reference","previous_headings":"","what":"Set annotations from a manifest — annotate_with_manifest","title":"Set annotations from a manifest — annotate_with_manifest","text":"Synapse docs suggest batch annotations fileview. However, often simpler modify set new annotations directly given table just entities (rows) props (cols) want. like schematic works, except without validation (works best power-users know data model well). desired defaults taken account, submitting key-values NA empty strings.","code":""},{"path":"/reference/annotate_with_manifest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set annotations from a manifest — annotate_with_manifest","text":"","code":"annotate_with_manifest(manifest, ignore_na = TRUE, ignore_blank = TRUE)"},{"path":"/reference/annotate_with_manifest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set annotations from a manifest — annotate_with_manifest","text":"manifest table manifest. Needs contain entityId. ignore_na Whether ignore annotations NA; default TRUE. ignore_blank Whether ignore annotations empty strings; default TRUE.","code":""},{"path":"/reference/annotate_with_tool_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Make annotations from workflow tool stats — annotate_with_tool_stats","title":"Make annotations from workflow tool stats — annotate_with_tool_stats","text":"Extracts subset samtools stats picard stats workflow metafiles surface annotations. Note: picard stats WGS/WES/targeted sequencing. Regarding selection stats, see Genomic Data Commons (GDC) model Aligned Reads","code":""},{"path":"/reference/annotate_with_tool_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make annotations from workflow tool stats — annotate_with_tool_stats","text":"","code":"annotate_with_tool_stats(   samtools_stats_file = NULL,   picard_stats_file = NULL,   sample_io = NULL )"},{"path":"/reference/annotate_with_tool_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make annotations from workflow tool stats — annotate_with_tool_stats","text":"samtools_stats_file Path file/syn id file samtools stats produced workflow. picard_stats_file Path file/syn id file picard stats produced workflow. sample_io Sample input output mapping, used assign stats appropriate outputs (bam)","code":""},{"path":"/reference/as_mmd_node.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for rendering nodes — as_mmd_node","title":"Helper function for rendering nodes — as_mmd_node","text":"Helper function rendering nodes","code":""},{"path":"/reference/as_mmd_node.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for rendering nodes — as_mmd_node","text":"","code":"as_mmd_node(entity, named = FALSE, class = c(\"Project\", \"Dataset\", \"Folder\"))"},{"path":"/reference/as_table_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform table data to target schema for Synapse storage — as_table_schema","title":"Transform table data to target schema for Synapse storage — as_table_schema","text":"Currently implements list-schema features first later. Check encode data values expectations Synapse target table schema storage. target schema likely existing table, since new tables can take advantage build_table. get compatible list data, JSON encoding optionally list_truncate running length limits. truncation OK, incompatibility resolved updating schema outside . Note setting applies list columns, though desirable column-specific.","code":""},{"path":"/reference/as_table_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform table data to target schema for Synapse storage — as_table_schema","text":"","code":"as_table_schema(df, schema, list_truncate = FALSE)"},{"path":"/reference/as_table_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform table data to target schema for Synapse storage — as_table_schema","text":"df table, .e. data.frame. schema Table schema object Synapse id target table get schema. list_truncate length exceeds schema max list columns, set TRUE allow data truncation, FALSE error (default).","code":""},{"path":"/reference/as_table_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform table data to target schema for Synapse storage — as_table_schema","text":"Synapse Table object ready storing.","code":""},{"path":"/reference/assign_study_data_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","title":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","text":"Summarize fileview annotations string-list column another table. example, use function summarize \"dataType\" annotations study STRINGLIST annotation Study table portal. Overwrites whatever currently target column.","code":""},{"path":"/reference/assign_study_data_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","text":"","code":"assign_study_data_types(   study_table_id,   fileview_id,   group_colname = \"studyId\",   source_colname = \"dataType\",   sep = \",\",   valid_values,   dry_run = TRUE )"},{"path":"/reference/assign_study_data_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","text":"study_table_id synapse id portal study table. Must write access. fileview_id Synapse ID portal fileview. group_colname column name group join (default = 'studyId') source_colname column name summarize add study_table_id table. column must exist schemas, must STRINGLIST-type column \"study_table_id\" table. sep delimited values exist source_colname column, pass delimiter cases included. valid_values vector valid values source_colname. e.g. output running get_valid_values_from_json_schema() dry_run Default = TRUE. Skips upload table instead prints study tibble.","code":""},{"path":"/reference/assign_study_data_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","text":"dry_run == T, returns study tibble skips upload.","code":""},{"path":"/reference/assign_study_data_types.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize file annotations into a STRINGLIST column on a study table. — assign_study_data_types","text":"","code":"if (FALSE) { assign_study_data_types(study_table_id = 'syn16787123',                         fileview_id = 'syn16858331',                         group_colname = 'studyId',                         source_colname = \"dataType\",                         sep = \",\",                         valid_values = get_valid_values_from_json_schema(),                         dry_run = T) }"},{"path":"/reference/bad_url.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to check urls — bad_url","title":"Helper function to check urls — bad_url","text":"Check whether URL(s) return HTTP error, indicating broken link. Note uses curl hood, may give timeout errors therefore false positives links valid take long resolve.","code":""},{"path":"/reference/bad_url.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to check urls — bad_url","text":"","code":"bad_url(url)"},{"path":"/reference/bad_url.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to check urls — bad_url","text":"url character vector one URLs.","code":""},{"path":"/reference/bad_url.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to check urls — bad_url","text":"Result vector size values \"bad\" \"ok\".","code":""},{"path":"/reference/bare_syn_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract synapse id from URI or other string — bare_syn_id","title":"Extract synapse id from URI or other string — bare_syn_id","text":"Extract synapse id URI string","code":""},{"path":"/reference/bare_syn_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract synapse id from URI or other string — bare_syn_id","text":"","code":"bare_syn_id(uri)"},{"path":"/reference/bare_syn_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract synapse id from URI or other string — bare_syn_id","text":"uri URI string containing embedded Synapse id.","code":""},{"path":"/reference/button_widget.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate button widget for a Synapse wiki — button_widget","title":"Generate button widget for a Synapse wiki — button_widget","text":"Generate markup button widget Synapse project wiki. Refer widget docs https://help.synapse.org/docs/Wikis.1975746682.html#Wikis-WikiWidgets. Buttons created sparingly strategically. See remove_button case future regret.","code":""},{"path":"/reference/button_widget.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate button widget for a Synapse wiki — button_widget","text":"","code":"button_widget(label, url, align = c(\"None\", \"Left\", \"Right\", \"Center\"))"},{"path":"/reference/button_widget.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate button widget for a Synapse wiki — button_widget","text":"label Button label text. url URL button link . align Button alignment, can one \"None\", \"Left\", \"Right\", \"Center\" (defaults \"None\").","code":""},{"path":"/reference/calc_study_dist_dtm.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate study distance based on summary text — calc_study_dist_dtm","title":"Calculate study distance based on summary text — calc_study_dist_dtm","text":"different measures similarity; gives cosine similarity based summary text, converted distance matrix. future, methods may used comparison ensemble.","code":""},{"path":"/reference/calc_study_dist_dtm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate study distance based on summary text — calc_study_dist_dtm","text":"","code":"calc_study_dist_dtm(studies)"},{"path":"/reference/calc_study_dist_dtm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate study distance based on summary text — calc_study_dist_dtm","text":"studies data.frame row \"document\"; summary studyId.","code":""},{"path":"/reference/calculate_related_studies.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate and add related studies to study table — calculate_related_studies","title":"Calculate and add related studies to study table — calculate_related_studies","text":"Processes study summary text identify clusters related studies. Calculates tf-idf values 1 2 length ngrams, clusters studies using ward.D clustering method. Updates data STRINGLIST column \"relatedStudies.\"","code":""},{"path":"/reference/calculate_related_studies.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate and add related studies to study table — calculate_related_studies","text":"","code":"calculate_related_studies(   study_table_id,   n_clust = NULL,   n_k = NULL,   dry_run = TRUE )"},{"path":"/reference/calculate_related_studies.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate and add related studies to study table — calculate_related_studies","text":"study_table_id synapse id portal study table. Must write access. n_clust Target number clusters generate using hierarchical clustering. practice, number total summaries divided 3 good starting point (100 studies = 33 clusters). given n_k ignored. n_k Generate target number closely related studies using k-nearest-neighbors instead; since number desired related studies specified, may preferable using n_clust, gives variable number related studies clusters vary size. Ignored n_clust already given. dry_run Default = TRUE. Skips upload table instead prints study tibble.","code":""},{"path":"/reference/calculate_related_studies.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate and add related studies to study table — calculate_related_studies","text":"dry_run == T, returns study tibble skips upload.","code":""},{"path":"/reference/calculate_related_studies.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate and add related studies to study table — calculate_related_studies","text":"","code":"if (FALSE) {  result1  <- calculate_related_studies(study_table_id = \"syn16787123\",                            n_clust = 40,                            dry_run = T) result2  <- calculate_related_studies(study_table_id = \"syn16787123\",                            n_k = 4,                            dry_run = T) x <- lapply(result1$relatedStudies, jsonlite::fromJSON) y <- lapply(result2$relatedStudies, jsonlite::fromJSON) # Compare mapply(function(x, y) sum(y %in% x), x, y)                                }"},{"path":"/reference/check_access.html","id":null,"dir":"Reference","previous_headings":"","what":"Check access — check_access","title":"Check access — check_access","text":"Check access","code":""},{"path":"/reference/check_access.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check access — check_access","text":"","code":"check_access(   id,   principal_id,   access_type = c(\"CREATE\", \"UPDATE\", \"CHANGE_SETTINGS\", \"DOWNLOAD\", \"MODERATE\", \"READ\",     \"CHANGE_PERMISSIONS\", \"DELETE\") )"},{"path":"/reference/check_access.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check access — check_access","text":"id benefactor entity. principal_id Group(s) check access type. access_type access type(s) check ; result summarizes whether permissions types specified.","code":""},{"path":"/reference/check_maf_release.html","id":null,"dir":"Reference","previous_headings":"","what":"Check maf file for release — check_maf_release","title":"Check maf file for release — check_maf_release","text":"Currently, simple check make sure released samples expected. may extended later needed.","code":""},{"path":"/reference/check_maf_release.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check maf file for release — check_maf_release","text":"","code":"check_maf_release(merged_maf, samplesheet)"},{"path":"/reference/check_maf_release.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check maf file for release — check_maf_release","text":"merged_maf Maf data data.table. samplesheet Samplesheet data.table.","code":""},{"path":"/reference/check_maf_release.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check maf file for release — check_maf_release","text":"Returns NULL everything OK, else sample ids match expectations.","code":""},{"path":"/reference/check_readpair_validity.html","id":null,"dir":"Reference","previous_headings":"","what":"Check fastq read pair matches samplesheet read pair assignment. — check_readpair_validity","title":"Check fastq read pair matches samplesheet read pair assignment. — check_readpair_validity","text":"Read pairs often encoded name file. , check encoded name file, samplesheet read pair (e.g. _1 _2) matches","code":""},{"path":"/reference/check_readpair_validity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check fastq read pair matches samplesheet read pair assignment. — check_readpair_validity","text":"","code":"check_readpair_validity(   samplesheet,   parse_fun = function(x) gsub(\"_T[0-9]$\", \"\", x) )"},{"path":"/reference/check_readpair_validity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check fastq read pair matches samplesheet read pair assignment. — check_readpair_validity","text":"samplesheet local file syn id samplesheet. parse_fun Function implementing parse samples samplesheet.","code":""},{"path":"/reference/check_readpair_validity.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check fastq read pair matches samplesheet read pair assignment. — check_readpair_validity","text":"","code":"if (FALSE) {  check_readpair_validity('syn39542932')  check_readpair_validity('syn29530880') }"},{"path":"/reference/check_wiki_links.html","id":null,"dir":"Reference","previous_headings":"","what":"Check wiki links — check_wiki_links","title":"Check wiki links — check_wiki_links","text":"primarily supports wiki quality control. method wraps helpers retrieve wiki content given project(s), extract URL(s) content, return list link check results per project wiki. Note main wiki page checked. well, remove/replace problematic link(s), still may false positive/negatives may need reviewed manually.","code":""},{"path":"/reference/check_wiki_links.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check wiki links — check_wiki_links","text":"","code":"check_wiki_links(project_id, to_table = TRUE)"},{"path":"/reference/check_wiki_links.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check wiki links — check_wiki_links","text":"project_id Character vector synapse project id(s) get wiki. to_table TRUE return results table else keep list. Additional downstream operations may prefer one .","code":""},{"path":"/reference/check_wiki_links.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check wiki links — check_wiki_links","text":"Depending to_table, list tibble projects links check results links. list include projects without links (empty list), table omit projects without links.","code":""},{"path":"/reference/check_wiki_links.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check wiki links — check_wiki_links","text":"","code":"if (FALSE) { check_wiki_links(project_id = c(\"syn11374354\",\"syn2343195\")) }"},{"path":"/reference/convert_to_stringlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a delimited string to a stringlist annotation — convert_to_stringlist","title":"Convert a delimited string to a stringlist annotation — convert_to_stringlist","text":"schema change operation updates 1) column type list 2) sets new max string length parameter Synapse Table (usually shrinking max value). can optionally consult metadata model good max string length. (might handle max list length future encoded model well). model consulted, built-check error thrown data model recognize key changed, .e. one wants strict key Table documented model. model involve (schema = NULL), max string length simply set based current values processing delimited list (original code).","code":""},{"path":"/reference/convert_to_stringlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a delimited string to a stringlist annotation — convert_to_stringlist","text":"","code":"convert_to_stringlist(   fileview_id,   annotation_key,   sep = \",\",   trim_ws = TRUE,   schema = NULL,   dry_run = TRUE )"},{"path":"/reference/convert_to_stringlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a delimited string to a stringlist annotation — convert_to_stringlist","text":"fileview_id synapse id fileview. Must desired annotations schema, must files annotate included scope. Must write access files want re-annotate. annotation_key character string annotation switch delimited string stringlist. sep delimiter character string. Default = \",\". trim_ws Remove white space beginning end list items (e.g. \"NF1, NF2\" \"NF1,NF2\" yield STRING_LIST result). Default = TRUE. schema Optional, path readable .jsonld schema use setting new col schema. See details. dry_run Skip upload table instead prints study tibble. Default = TRUE.","code":""},{"path":"/reference/convert_to_stringlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a delimited string to a stringlist annotation — convert_to_stringlist","text":"dry_run == T, returns list updates skips upload.","code":""},{"path":"/reference/copy.html","id":null,"dir":"Reference","previous_headings":"","what":"Create copy of entity — copy","title":"Create copy of entity — copy","text":"Create copy syn entity; mostly used create copy test changes. See https://python-docs.synapse.org/build/html/synapseutils.html?highlight=copy#synapseutils.copy_functions.copy","code":""},{"path":"/reference/copy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create copy of entity — copy","text":"","code":"copy(   entity,   destination_id,   skip_copy_wiki_page = FALSE,   skip_copy_annotations = FALSE )"},{"path":"/reference/copy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create copy of entity — copy","text":"entity Entity copy. destination_id Id destination project/container entity copied . skip_copy_wiki_page Whether skip copying wiki; defaults FALSE. skip_copy_annotations Whether skip copying annotations; defaults FALSE.","code":""},{"path":"/reference/copy_annotations.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy annotations — copy_annotations","title":"Copy annotations — copy_annotations","text":"Copy annotations (selectively) source entity one target entities. annotations already exist target entities, copy replace current values.","code":""},{"path":"/reference/copy_annotations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy annotations — copy_annotations","text":"","code":"copy_annotations(entity_from, entity_to, select = NULL, update = FALSE)"},{"path":"/reference/copy_annotations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy annotations — copy_annotations","text":"entity_from Syn id copy. entity_to One syn ids copy annotations . select Vector properties selectively copy present entity. specified, copy everything, may desirable. update Whether immediately update return annotation objects .","code":""},{"path":"/reference/data_curator_app_subpage.html","id":null,"dir":"Reference","previous_headings":"","what":"Create NF Data Curator App subpage — data_curator_app_subpage","title":"Create NF Data Curator App subpage — data_curator_app_subpage","text":"Convenience method create subpage default buttons annotation app docs. highly specific method expected limited lifespan.","code":""},{"path":"/reference/data_curator_app_subpage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create NF Data Curator App subpage — data_curator_app_subpage","text":"","code":"data_curator_app_subpage(project_id, dry_run = TRUE)"},{"path":"/reference/data_curator_app_subpage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create NF Data Curator App subpage — data_curator_app_subpage","text":"project_id ID owner Synapse project. dry_run Whether return wiki object without actually performing update.","code":""},{"path":"/reference/delete_provenance.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove provenance info — delete_provenance","title":"Remove provenance info — delete_provenance","text":"Remove provenance info","code":""},{"path":"/reference/delete_provenance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove provenance info — delete_provenance","text":"","code":"delete_provenance(entities)"},{"path":"/reference/delete_provenance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove provenance info — delete_provenance","text":"entities Vector list entities.","code":""},{"path":"/reference/derive_annotations.html","id":null,"dir":"Reference","previous_headings":"","what":"Derive annotations for processed output data — derive_annotations","title":"Derive annotations for processed output data — derive_annotations","text":"Build annotations inheritance inputs. multiple inputs, inherit props FIRST input. Files pass naturally dataSubtype set \"processed\" fileFormat set actual new file format. future, template may define format need specify explicitly.","code":""},{"path":"/reference/derive_annotations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Derive annotations for processed output data — derive_annotations","text":"","code":"derive_annotations(sample_io, template, schema, format, verbose = TRUE)"},{"path":"/reference/derive_annotations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Derive annotations for processed output data — derive_annotations","text":"format File format processed data, e.g. \"vcf\".","code":""},{"path":"/reference/dot-add_publication_from_pubmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Higher-level fun to generate add_publication_from_pubmed util for one-off usage (default) or optimized for batch processing. — .add_publication_from_pubmed","title":"Higher-level fun to generate add_publication_from_pubmed util for one-off usage (default) or optimized for batch processing. — .add_publication_from_pubmed","text":"Higher-level fun generate add_publication_from_pubmed util one-usage (default) optimized batch processing.","code":""},{"path":"/reference/dot-add_publication_from_pubmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Higher-level fun to generate add_publication_from_pubmed util for one-off usage (default) or optimized for batch processing. — .add_publication_from_pubmed","text":"","code":".add_publication_from_pubmed(batch = 0L, cache = batch)"},{"path":"/reference/dot-add_publication_from_pubmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Higher-level fun to generate add_publication_from_pubmed util for one-off usage (default) or optimized for batch processing. — .add_publication_from_pubmed","text":"batch non-zero batch size, turns batch mode; defaults -batch. cache Whether cache results, default batch.","code":""},{"path":"/reference/dot-check_login.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks .syn object exists. — .check_login","title":"Checks .syn object exists. — .check_login","text":"Checks .syn object exists.","code":""},{"path":"/reference/dot-check_login.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks .syn object exists. — .check_login","text":"","code":".check_login()"},{"path":"/reference/dot-check_login.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks .syn object exists. — .check_login","text":"message.","code":""},{"path":"/reference/dot-delim_string_to_vector.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a delimited string to vector, utility function. — .delim_string_to_vector","title":"Convert a delimited string to vector, utility function. — .delim_string_to_vector","text":"Converts delimited string stringlist annotation adjust associated schema portal fileview.","code":""},{"path":"/reference/dot-delim_string_to_vector.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a delimited string to vector, utility function. — .delim_string_to_vector","text":"","code":".delim_string_to_vector(string, sep, trim_ws = T)"},{"path":"/reference/dot-delim_string_to_vector.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a delimited string to vector, utility function. — .delim_string_to_vector","text":"string character string. sep Default = \",\". delimiter character string. trim_ws Default = TRUE. Remove white space beginning end list items (e.g. \"NF1, NF2\" \"NF1,NF2\" yield STRING_LIST result).","code":""},{"path":"/reference/dot-modify_annotation.html","id":null,"dir":"Reference","previous_headings":"","what":"Modify a single annotation on a single file — .modify_annotation","title":"Modify a single annotation on a single file — .modify_annotation","text":"Modifies single annotation value single (existing) synapse file.","code":""},{"path":"/reference/dot-modify_annotation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modify a single annotation on a single file — .modify_annotation","text":"","code":".modify_annotation(synapse_id, key, value)"},{"path":"/reference/dot-modify_annotation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modify a single annotation on a single file — .modify_annotation","text":"synapse_id synapse entity id. key key annotation modify. value value change annotation .","code":""},{"path":"/reference/dot-replace_string_column_with_stringlist_column.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace string column with stringlist column — .replace_string_column_with_stringlist_column","title":"Replace string column with stringlist column — .replace_string_column_with_stringlist_column","text":"Guts ripped @jaeddy gist (https://gist.github.com/jaeddy/1cf49f7851945beedb39d431134734af)","code":""},{"path":"/reference/dot-replace_string_column_with_stringlist_column.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace string column with stringlist column — .replace_string_column_with_stringlist_column","text":"","code":".replace_string_column_with_stringlist_column(   table_id,   column_name,   max_str_len )"},{"path":"/reference/dot-replace_string_column_with_stringlist_column.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace string column with stringlist column — .replace_string_column_with_stringlist_column","text":"table_id synapse entity id. column_name column name relevant column modify. max_str_len Max string length set schema new column.","code":""},{"path":"/reference/dot-store_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a row to a table. — .store_rows","title":"Adds a row to a table. — .store_rows","text":"Adds row table.","code":""},{"path":"/reference/dot-store_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a row to a table. — .store_rows","text":"","code":".store_rows(schema, new_row)"},{"path":"/reference/dot-store_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a row to a table. — .store_rows","text":"schema synapse table Schema object. new_row data frame one rows match provided schema.","code":""},{"path":"/reference/dot-update_table_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace/update table contents = input data must have ROW_ID and ROW_VERSION columns to update, otherwise will append data. — .update_table_data","title":"Replace/update table contents = input data must have ROW_ID and ROW_VERSION columns to update, otherwise will append data. — .update_table_data","text":"Replace/update table contents = input data must ROW_ID ROW_VERSION columns update, otherwise append data.","code":""},{"path":"/reference/dot-update_table_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace/update table contents = input data must have ROW_ID and ROW_VERSION columns to update, otherwise will append data. — .update_table_data","text":"","code":".update_table_data(table_id, new_data, etag = NULL)"},{"path":"/reference/dot-update_table_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace/update table contents = input data must have ROW_ID and ROW_VERSION columns to update, otherwise will append data. — .update_table_data","text":"table_id synapse id table update. new_data updated table. etag etag latest version table. provided, query table_id retrieve latest etag.","code":""},{"path":"/reference/dot-update_view_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace/update table contents = input data must have ROW_ID, ROW_VERSION, ETAG columns to update. — .update_view_data","title":"Replace/update table contents = input data must have ROW_ID, ROW_VERSION, ETAG columns to update. — .update_view_data","text":"Replace/update table contents = input data must ROW_ID, ROW_VERSION, ETAG columns update.","code":""},{"path":"/reference/dot-update_view_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace/update table contents = input data must have ROW_ID, ROW_VERSION, ETAG columns to update. — .update_view_data","text":"","code":".update_view_data(table_id, new_data)"},{"path":"/reference/dot-update_view_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace/update table contents = input data must have ROW_ID, ROW_VERSION, ETAG columns to update. — .update_view_data","text":"table_id synapse id table update. new_data updated table.","code":""},{"path":"/reference/dt_read.html","id":null,"dir":"Reference","previous_headings":"","what":"Download and read file to data.table — dt_read","title":"Download and read file to data.table — dt_read","text":"Convenience function reading delimited local file one Synapse.","code":""},{"path":"/reference/dt_read.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download and read file to data.table — dt_read","text":"","code":"dt_read(file)"},{"path":"/reference/from_pubmed.html","id":null,"dir":"Reference","previous_headings":"","what":"Get publication metadata from PubMed — from_pubmed","title":"Get publication metadata from PubMed — from_pubmed","text":"Get publication metadata PubMed","code":""},{"path":"/reference/from_pubmed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get publication metadata from PubMed — from_pubmed","text":"","code":"from_pubmed(pmid)"},{"path":"/reference/from_pubmed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get publication metadata from PubMed — from_pubmed","text":"pmid PubMed id.","code":""},{"path":"/reference/from_pubmed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get publication metadata from PubMed — from_pubmed","text":"PMID found, return meta table w/ title  journal  author  year  pmid  doi.","code":""},{"path":"/reference/get_by_prop_from_json_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Look up connected nodes by specified property in JSON-LD schema — get_by_prop_from_json_schema","title":"Look up connected nodes by specified property in JSON-LD schema — get_by_prop_from_json_schema","text":"Use schematic-generated JSON-LD schema: given @id, get connected nodes specified prop (e.g. sms:something). Intended generic used define specific lookup utils. Can recursive lookup, though graph tree/acyclic (!). (Useful props dependsOn, make sense props rdfs:label.)","code":""},{"path":"/reference/get_by_prop_from_json_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Look up connected nodes by specified property in JSON-LD schema — get_by_prop_from_json_schema","text":"","code":"get_by_prop_from_json_schema(   id,   prop,   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   return_labels = TRUE,   recursive = FALSE,   result = NULL,   rest = NULL )"},{"path":"/reference/get_by_prop_from_json_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Look up connected nodes by specified property in JSON-LD schema — get_by_prop_from_json_schema","text":"id Id (@id) get range values; include prefix needed. prop Property; include prefix needed. schema Path (URL local) file schema read, schema list object. return_labels Return labels (default), otherwise ids connected nodes. recursive Recursive lookup? result Vector accumulated results; used recursive lookup. rest Vector remaining ids; used recursive lookup.","code":""},{"path":"/reference/get_cbio_filename.html","id":null,"dir":"Reference","previous_headings":"","what":"Get cBioPortal clinical file name based on clinical data type — get_cbio_filename","title":"Get cBioPortal clinical file name based on clinical data type — get_cbio_filename","text":"called wrapper write_cbio_clinical. Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_clinical.R#L411. Note clinical file types, PATIENT type can actually optional, (NF) currently use TIMELINE type, options simplified.","code":""},{"path":"/reference/get_cbio_filename.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get cBioPortal clinical file name based on clinical data type — get_cbio_filename","text":"","code":"get_cbio_filename(clinical_type = c(\"SAMPLE\", \"PATIENT\"))"},{"path":"/reference/get_cbio_filename.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get cBioPortal clinical file name based on clinical data type — get_cbio_filename","text":"clinical_type String representing cBioPortal clinical data type.","code":""},{"path":"/reference/get_cbio_filename.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get cBioPortal clinical file name based on clinical data type — get_cbio_filename","text":"string","code":""},{"path":"/reference/get_data_for_releasable.html","id":null,"dir":"Reference","previous_headings":"","what":"Download data from a view for releasable samples in samplesheet — get_data_for_releasable","title":"Download data from a view for releasable samples in samplesheet — get_data_for_releasable","text":"tries check complete data retrieved said view. Note: Since view typically denormalized, data might clinical. downstream step additional processing/subsetting needed.","code":""},{"path":"/reference/get_data_for_releasable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download data from a view for releasable samples in samplesheet — get_data_for_releasable","text":"","code":"get_data_for_releasable(samplesheet, ref_view, verbose = TRUE)"},{"path":"/reference/get_data_for_releasable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download data from a view for releasable samples in samplesheet — get_data_for_releasable","text":"samplesheet Samplesheet data.table. ref_view View get data . verbose Output details.","code":""},{"path":"/reference/get_dependency_from_json_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dependencies for node in JSON-LD schema — get_dependency_from_json_schema","title":"Get dependencies for node in JSON-LD schema — get_dependency_from_json_schema","text":"Shorthand getting props defined annotation template using get_by_prop_from_json_schema hood.","code":""},{"path":"/reference/get_dependency_from_json_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dependencies for node in JSON-LD schema — get_dependency_from_json_schema","text":"","code":"get_dependency_from_json_schema(   id,   prop = \"sms:requiresDependency\",   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   return_labels = TRUE,   recursive = TRUE,   result = NULL,   rest = NULL )"},{"path":"/reference/get_dependency_from_json_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dependencies for node in JSON-LD schema — get_dependency_from_json_schema","text":"id Id (@id) get range values; include prefix needed. prop Property; include prefix needed. schema Path (URL local) file schema read, schema list object. return_labels Return labels (default), otherwise ids connected nodes. recursive Recursive lookup? result Vector accumulated results; used recursive lookup. rest Vector remaining ids; used recursive lookup.","code":""},{"path":"/reference/get_gs_project_tracking.html","id":null,"dir":"Reference","previous_headings":"","what":"Get and parse data from Google Sheets for initializing a new project — get_gs_project_tracking","title":"Get and parse data from Google Sheets for initializing a new project — get_gs_project_tracking","text":"Notice: DEPRECATED removed next version. Currently, project tracking data stored private GoogleSheet. new_project, wraps googlesheets4 get needed data.","code":""},{"path":"/reference/get_gs_project_tracking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get and parse data from Google Sheets for initializing a new project — get_gs_project_tracking","text":"","code":"get_gs_project_tracking(   sheet,   creds = NULL,   cols = c(name = \"studyName\", pi = \"studyPI\", lead = \"studyLeads\", admin_user = NULL,     abstract = \"abstract\", institution = \"institutions\", funder = \"fundingAgency\",     initiative = \"initiative\", disease = \"diseaseFocus\", manifestations =     \"diseaseManifestations\", grant_doi = \"grantDOI\") )  get_project_tracking(   sheet,   creds = NULL,   cols = c(name = \"studyName\", pi = \"studyPI\", lead = \"studyLeads\", admin_user = NULL,     abstract = \"abstract\", institution = \"institutions\", funder = \"fundingAgency\",     initiative = \"initiative\", disease = \"diseaseFocus\", manifestations =     \"diseaseManifestations\", grant_doi = \"grantDOI\") )"},{"path":"/reference/get_gs_project_tracking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get and parse data from Google Sheets for initializing a new project — get_gs_project_tracking","text":"sheet Sheet URL id. See read_sheet. creds Path JSON creds file (service account token). cols List columns map required parameters new_project. Defaults provided.","code":""},{"path":"/reference/get_gs_project_tracking.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get and parse data from Google Sheets for initializing a new project — get_gs_project_tracking","text":"creds provided, .e. service account token, usage requires authenticating Tidyverse API browser get API token behalf. actually give googlesheets4 project access data (\"Tidyverse API Packages project never receives data permission access data.\" -- see https://www.tidyverse.org/google_privacy_policy/.)","code":""},{"path":"/reference/get_project_wiki.html","id":null,"dir":"Reference","previous_headings":"","what":"Get wiki content of synapse project(s) — get_project_wiki","title":"Get wiki content of synapse project(s) — get_project_wiki","text":"Get wiki object text content (main page ). primarily helper function used QC may useful wiki analysis.","code":""},{"path":"/reference/get_project_wiki.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get wiki content of synapse project(s) — get_project_wiki","text":"","code":"get_project_wiki(project_id, markdown = TRUE)"},{"path":"/reference/get_project_wiki.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get wiki content of synapse project(s) — get_project_wiki","text":"project_id Character vector synapse project id(s) get wiki. markdown TRUE (default) return markdown text, else return full wiki object.","code":""},{"path":"/reference/get_project_wiki.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get wiki content of synapse project(s) — get_project_wiki","text":"list storing wiki object markdown-formatted text.","code":""},{"path":"/reference/get_project_wiki.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get wiki content of synapse project(s) — get_project_wiki","text":"","code":"if (FALSE) {  txt <- get_project_wiki(c(\"syn11374354\",\"syn2343195\")) }"},{"path":"/reference/get_valid_values_from_json_schema.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve valid subclasses of a value in a JSON-LD schema — get_valid_values_from_json_schema","title":"Retrieve valid subclasses of a value in a JSON-LD schema — get_valid_values_from_json_schema","text":"Retrieve valid subclasses value JSON-LD schema generated schematic.","code":""},{"path":"/reference/get_valid_values_from_json_schema.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve valid subclasses of a value in a JSON-LD schema — get_valid_values_from_json_schema","text":"","code":"get_valid_values_from_json_schema(   schema_url =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   parent_name = \"DataType\",   parent_context = \"bts\" )"},{"path":"/reference/get_valid_values_from_json_schema.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve valid subclasses of a value in a JSON-LD schema — get_valid_values_from_json_schema","text":"schema_url Default: NF-OSI JSON-LD schema. parent_name Default = DataType. value like find associated subclasses. parent_context Default = bts. JSON-LD context value question.","code":""},{"path":"/reference/get_valid_values_from_json_schema.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve valid subclasses of a value in a JSON-LD schema — get_valid_values_from_json_schema","text":"character vector values.","code":""},{"path":"/reference/grant_specific_file_access.html","id":null,"dir":"Reference","previous_headings":"","what":"Provide access to a specific set of files using a query result. — grant_specific_file_access","title":"Provide access to a specific set of files using a query result. — grant_specific_file_access","text":"Sets READ/DOWNLOAD permissions specific user team, provided vector entity IDs. Generally, set permissions way, can create many, many ACLs/\"local sharing settings\" need removed time data publication. However, time writing, one project (JHU Biobank) shares embargoed data required share specific subsets files needed data requestor (e.g. MPNST tumor data, RNA-seq data).","code":""},{"path":"/reference/grant_specific_file_access.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provide access to a specific set of files using a query result. — grant_specific_file_access","text":"","code":"grant_specific_file_access(   principal_id,   entity_ids,   create_dataset = F,   project_id = NULL,   dataset_name = NULL )"},{"path":"/reference/grant_specific_file_access.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provide access to a specific set of files using a query result. — grant_specific_file_access","text":"principal_id Synapse team user id. entity_ids Vector entity ids. create_dataset Optionally, create dataset entity_ids, user can easily retrieve . project_id create_dataset=T, project create . dataset_name Optional name dataset created","code":""},{"path":"/reference/identify_read_pair.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify read pair from string — identify_read_pair","title":"Identify read pair from string — identify_read_pair","text":"Identify read pair string","code":""},{"path":"/reference/identify_read_pair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify read pair from string — identify_read_pair","text":"","code":"identify_read_pair(string)"},{"path":"/reference/identify_read_pair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify read pair from string — identify_read_pair","text":"string filename string.","code":""},{"path":"/reference/identify_read_pair.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify read pair from string — identify_read_pair","text":"Returns read pair: 1, 2, NULL none detected.","code":""},{"path":"/reference/key_label_to_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Query for schema key id given label — key_label_to_id","title":"Query for schema key id given label — key_label_to_id","text":"Utility translate label id using schematic-generated schema.","code":""},{"path":"/reference/key_label_to_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query for schema key id given label — key_label_to_id","text":"","code":"key_label_to_id(   label,   prefixed = TRUE,   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\" )"},{"path":"/reference/key_label_to_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query for schema key id given label — key_label_to_id","text":"label term label, .k.display name. prefixed Boolean indicate whether include namespace prefix return bare ID. Defaults TRUE. schema URL local path .jsonld file schema read .","code":""},{"path":"/reference/key_label_to_id.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query for schema key id given label — key_label_to_id","text":"id found, \"bts:MyID\", otherwise empty character vector.","code":""},{"path":"/reference/make_admin.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a user or group full admin of a Synapse entity — make_admin","title":"Make a user or group full admin of a Synapse entity — make_admin","text":"Convenience method set admin permissions","code":""},{"path":"/reference/make_admin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a user or group full admin of a Synapse entity — make_admin","text":"","code":"make_admin(entity, principal_id)"},{"path":"/reference/make_admin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a user or group full admin of a Synapse entity — make_admin","text":"entity Synapse entity, e.g. project folder. principal_id User team id configured access entity.","code":""},{"path":"/reference/make_cbio_clinical_header.html","id":null,"dir":"Reference","previous_headings":"","what":"Make header for cBioPortal clinical data file — make_cbio_clinical_header","title":"Make header for cBioPortal clinical data file — make_cbio_clinical_header","text":"called wrapper write_cbio_clinical. Reused https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_clinical.R#L396.","code":""},{"path":"/reference/make_cbio_clinical_header.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make header for cBioPortal clinical data file — make_cbio_clinical_header","text":"","code":"make_cbio_clinical_header(df, label, description, data_type)"},{"path":"/reference/make_cbio_clinical_header.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make header for cBioPortal clinical data file — make_cbio_clinical_header","text":"df data.frame representing clinical dataset publicize. label Character vector representing short label column dataset description Character vector representing long descriptions column dataset data_type Character vector representing data type column dataset","code":""},{"path":"/reference/make_folder.html","id":null,"dir":"Reference","previous_headings":"","what":"Create project folders — make_folder","title":"Create project folders — make_folder","text":"Use set scaffold standard upper-level folders well customized data folders within \"Raw Data\" new project.","code":""},{"path":"/reference/make_folder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create project folders — make_folder","text":"","code":"make_folder(parent, folders)"},{"path":"/reference/make_folder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create project folders — make_folder","text":"parent Synapse id object parent container, .e. project another folder. folders List giving one folder names folder(s) create.","code":""},{"path":"/reference/make_folder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create project folders — make_folder","text":"list created folder object(s).","code":""},{"path":"/reference/make_folder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create project folders — make_folder","text":"","code":"if (FALSE) {  datasets <- list(\"sequencing data\", \"imaging data\") assays <- c(\"rnaSeq\", \"immunohistochemistry\") for(i in seq_along(datasets)) attr(datasets[[i]], \"assay\") <- assays[[i]]  make_folder(parent = \"syn26462036\", datasets)   }"},{"path":"/reference/make_meta_clinical_generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic template for clinical data file — make_meta_clinical_generic","title":"Generic template for clinical data file — make_meta_clinical_generic","text":"Make meta file describe one clinical data files (e.g. SAMPLE, PATIENT). Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/make_meta.R#L65","code":""},{"path":"/reference/make_meta_clinical_generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic template for clinical data file — make_meta_clinical_generic","text":"","code":"make_meta_clinical_generic(   cancer_study_identifier,   genetic_alteration_type,   datatype,   data_filename )"},{"path":"/reference/make_meta_clinical_generic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic template for clinical data file — make_meta_clinical_generic","text":"cancer_study_identifier study identifier. genetic_alteration_type cBioPortal generic alteration type. datatype cBioPortal data type data_filename. data_filename Name data file meta file describes.","code":""},{"path":"/reference/make_meta_genomic_generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic template for genomic-type data file — make_meta_genomic_generic","title":"Generic template for genomic-type data file — make_meta_genomic_generic","text":"Reused https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/make_meta.R#L65","code":""},{"path":"/reference/make_meta_genomic_generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic template for genomic-type data file — make_meta_genomic_generic","text":"","code":"make_meta_genomic_generic(   cancer_study_identifier,   genetic_alteration_type,   datatype,   stable_id,   profile_name,   profile_description,   data_filename )"},{"path":"/reference/make_meta_genomic_generic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic template for genomic-type data file — make_meta_genomic_generic","text":"cancer_study_identifier study identifier. genetic_alteration_type cBioPortal generic alteration type. datatype cBioPortal data type data_filename. stable_id Stable id. profile_name Name genomic profiling. set specific make_meta utility. example, \"Mutations\" make_*_maf \"Copy-number alterations\" make_*_cna. profile_description Brief description genomic profiling. set specific make_meta utility. data_filename Name data file meta file describes.","code":""},{"path":"/reference/make_meta_maf.html","id":null,"dir":"Reference","previous_headings":"","what":"Make meta file for maf — make_meta_maf","title":"Make meta file for maf — make_meta_maf","text":"Reused https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/make_meta.R#L157","code":""},{"path":"/reference/make_meta_maf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make meta file for maf — make_meta_maf","text":"","code":"make_meta_maf(   cancer_study_identifier,   data_filename = \"data_mutations_extended.txt\",   publish_dir = \".\",   write = TRUE,   verbose = TRUE )"},{"path":"/reference/make_meta_maf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make meta file for maf — make_meta_maf","text":"cancer_study_identifier study identifier. data_filename Name data file. Defaults \"data_mutations_extended.txt\". publish_dir Directory path write , defaults current. write Whether write meta file data file. verbose Report file written.","code":""},{"path":"/reference/make_meta_patient.html","id":null,"dir":"Reference","previous_headings":"","what":"Make patient meta file — make_meta_patient","title":"Make patient meta file — make_meta_patient","text":"Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_meta.R#L101","code":""},{"path":"/reference/make_meta_patient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make patient meta file — make_meta_patient","text":"","code":"make_meta_patient(   cancer_study_identifier,   data_filename = \"data_clinical_patient.txt\",   write = TRUE,   publish_dir = \".\",   verbose = TRUE )"},{"path":"/reference/make_meta_patient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make patient meta file — make_meta_patient","text":"cancer_study_identifier study identifier. data_filename Name data file meta file describes. write Whether write meta file clinical data file. publish_dir Directory path write , defaults current. verbose Report file written.","code":""},{"path":"/reference/make_meta_sample.html","id":null,"dir":"Reference","previous_headings":"","what":"Make sample meta file — make_meta_sample","title":"Make sample meta file — make_meta_sample","text":"Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_meta.R#L109","code":""},{"path":"/reference/make_meta_sample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make sample meta file — make_meta_sample","text":"","code":"make_meta_sample(   cancer_study_identifier,   data_filename = \"data_clinical_sample.txt\",   publish_dir = \".\",   write = TRUE,   verbose = TRUE )"},{"path":"/reference/make_meta_sample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make sample meta file — make_meta_sample","text":"cancer_study_identifier study identifier. data_filename Name data file meta file describes. publish_dir Directory path write , defaults current. write Whether write meta file clinical data file. verbose Report file written.","code":""},{"path":"/reference/make_meta_study.html","id":null,"dir":"Reference","previous_headings":"","what":"Make meta study file — make_meta_study","title":"Make meta study file — make_meta_study","text":"Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_meta.R#L179 See specifications https://docs.cbioportal.org/file-formats/#meta-file.","code":""},{"path":"/reference/make_meta_study.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make meta study file — make_meta_study","text":"","code":"make_meta_study(   cancer_study_identifier,   type_of_cancer = \"mixed\",   name,   description,   citation = NULL,   pmid = NULL,   groups = \"PUBLIC\",   short_name = NULL,   add_global_case_list = TRUE,   publish_dir = \".\",   write = TRUE,   verbose = TRUE )"},{"path":"/reference/make_meta_study.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make meta study file — make_meta_study","text":"cancer_study_identifier study identifier. type_of_cancer Type cancer, defaults \"mixed\". See also http://oncotree.mskcc.org/#/home. name Name study. description Description study. citation (Optional) relevant citation, e.g. \"TCGA, Nature 2012\". pmid (Optional) One relevant pubmed ids (comma separated without whitespace); used, citation NULL. groups (Optional) Defaults \"PUBLIC\" use public cBioPortal; otherwise, use group names make sense instance. short_name (Optional) Short name study. add_global_case_list (Optional) Use NULL ignore, default TRUE \"samples\" case list generated automatically. publish_dir Directory path write , defaults current. write Whether write meta file clinical data file. verbose Report file written.","code":""},{"path":"/reference/make_meta_study_generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Template for meta study file — make_meta_study_generic","title":"Template for meta study file — make_meta_study_generic","text":"Adapted https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_meta.R#L90 Low-level internal function tedious templating.","code":""},{"path":"/reference/make_meta_study_generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Template for meta study file — make_meta_study_generic","text":"","code":"make_meta_study_generic(   type_of_cancer,   cancer_study_identifier,   name,   description,   citation = NULL,   pmid = NULL,   groups = NULL,   short_name = NULL,   add_global_case_list = NULL )"},{"path":"/reference/make_public.html","id":null,"dir":"Reference","previous_headings":"","what":"Make public — make_public","title":"Make public — make_public","text":"Sets READ/DOWNLOAD permissions web registered users equivalently \"Make Public\" button Synapse UI. TODO: regular users can one--done action, DCC admin likely entails actions, updating project tracking table, wrapper \"callback\" functionality might needed.","code":""},{"path":"/reference/make_public.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make public — make_public","text":"","code":"make_public(id)"},{"path":"/reference/make_public.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make public — make_public","text":"id Synapse entity id.","code":""},{"path":"/reference/map_reports_sarek.html","id":null,"dir":"Reference","previous_headings":"","what":"Map out Sarek report files — map_reports_sarek","title":"Map out Sarek report files — map_reports_sarek","text":"family helper funs annotate secondary report files certain nextflow workflows. Sarek, many report files conveniently outputted top-level \"Reports\" folder, organize reports sample tool (BFCTools, FastQC, etc.). example reference starting sample-level: https://www.synapse.org/#!Synapse:syn31665258 things \"Reports\" can indeed generally called \"workflow report\" (subclass \"report\" resource), files bamQC reports directory misc web assets (.css, .js, .gif, etc.) used HTML report. HTML reports asset files directly embedded/bundled .html file, misc files become extra annotation burden. Since debatable call something like .css file report, files classified instead \"report asset\".","code":""},{"path":"/reference/map_reports_sarek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map out Sarek report files — map_reports_sarek","text":"","code":"map_reports_sarek(syn_out, project)"},{"path":"/reference/map_reports_sarek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map out Sarek report files — map_reports_sarek","text":"syn_out Reports output folder set scope fileview. project Project put fileview.","code":""},{"path":"/reference/map_reports_sarek.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map out Sarek report files — map_reports_sarek","text":"Unlike map_* functions, requires fileview instead using walk create one.","code":""},{"path":"/reference/map_sample_input_ss.html","id":null,"dir":"Reference","previous_headings":"","what":"Parse nextflow samplesheet for sample inputs — map_sample_input_ss","title":"Parse nextflow samplesheet for sample inputs — map_sample_input_ss","text":"Samplesheets used rnaseq pipelines, defined : https://nf-co.re/rnaseq/usage#full-samplesheet. pipeline run, found output folder called pipeline_info. simple helper get mapping sample ids input files (either one--many one--one) table.","code":""},{"path":"/reference/map_sample_input_ss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parse nextflow samplesheet for sample inputs — map_sample_input_ss","text":"","code":"map_sample_input_ss(   samplesheet,   parse_fun = function(x) gsub(\"_T[0-9]$\", \"\", x) )"},{"path":"/reference/map_sample_input_ss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parse nextflow samplesheet for sample inputs — map_sample_input_ss","text":"samplesheet local file syn id samplesheet. parse_fun Function implementing parse samples samplesheet.","code":""},{"path":"/reference/map_sample_io.html","id":null,"dir":"Reference","previous_headings":"","what":"Map sample input-output — map_sample_io","title":"Map sample input-output — map_sample_io","text":"Wrapper map sample inputs outputs depending workflow type.","code":""},{"path":"/reference/map_sample_io.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map sample input-output — map_sample_io","text":"","code":"map_sample_io(workflow = c(\"nf-rnaseq\", \"nf-sarek\"), samplesheet, syn_out)"},{"path":"/reference/map_sample_io.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map sample input-output — map_sample_io","text":"workflow Workflow. samplesheet local file syn id samplesheet. syn_out Syn id syn output destination files interest.","code":""},{"path":"/reference/map_sample_io.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map sample input-output — map_sample_io","text":"table sample  level  output_id  output_name  input_id.","code":""},{"path":"/reference/map_sample_output_rnaseq.html","id":null,"dir":"Reference","previous_headings":"","what":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","title":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","text":"See https://nf-co.re/rnaseq. Given location workflow deposited outputs, map relevant processed files based extensions link files source samples. results/star_salmon/<sample>/<file>, URI pass star_salmon folder. Warning: Reliance certain file structure naming convention can make somewhat brittle!","code":""},{"path":"/reference/map_sample_output_rnaseq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","text":"","code":"map_sample_output_rnaseq(syn_out)"},{"path":"/reference/map_sample_output_rnaseq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","text":"syn_out Syn id syn output destination files interest.","code":""},{"path":"/reference/map_sample_output_rnaseq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","text":"data.table cols output_name  output_id  sample  workflow","code":""},{"path":"/reference/map_sample_output_rnaseq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map sample to output from nf-rnaseq — map_sample_output_rnaseq","text":"See related map_sample_input_ss mapping sample inputs instead outputs.","code":""},{"path":"/reference/map_sample_output_sarek.html","id":null,"dir":"Reference","previous_headings":"","what":"Map sample to output from nf-sarek — map_sample_output_sarek","title":"Map sample to output from nf-sarek — map_sample_output_sarek","text":"See https://nf-co.re/sarek. Processed outputs nested sample variant callers, .e. *VariantCalling/<TUMOR_vs_NORMAL>/<CALLER>. walks output destination (URI *VariantCalling) similar intention map_sample_output_rnaseq, Sarek outputs.","code":""},{"path":"/reference/map_sample_output_sarek.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map sample to output from nf-sarek — map_sample_output_sarek","text":"","code":"map_sample_output_sarek(syn_out)"},{"path":"/reference/map_sample_output_sarek.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map sample to output from nf-sarek — map_sample_output_sarek","text":"syn_out Syn id syn output destination files interest.","code":""},{"path":"/reference/map_sample_output_sarek.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map sample to output from nf-sarek — map_sample_output_sarek","text":"data.table cols caller  caller_path  caller_syn  output_name  output_id  sample  workflow","code":""},{"path":"/reference/map_sample_output_sarek.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Map sample to output from nf-sarek — map_sample_output_sarek","text":"Note: additional step post-Sarek create MAFs output subdirectory DeepVariant. run MAF creation step, return file indexes .maf files.","code":""},{"path":"/reference/match_maf_sample_id.html","id":null,"dir":"Reference","previous_headings":"","what":"Match clinical data with maf sample ids — match_maf_sample_id","title":"Match clinical data with maf sample ids — match_maf_sample_id","text":"PATIENT_ID SAMPLE_ID can contain letters, numbers, points, underscores /hyphens. nf processing, sample id spaces replaced underscores maf, applied clinical data match.","code":""},{"path":"/reference/match_maf_sample_id.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Match clinical data with maf sample ids — match_maf_sample_id","text":"","code":"match_maf_sample_id(clinical_data, merged_maf = NULL)"},{"path":"/reference/match_maf_sample_id.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Match clinical data with maf sample ids — match_maf_sample_id","text":"clinical_data Clinical data data.table. merged_maf Maf data data.table.","code":""},{"path":"/reference/missing_annotation_email.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a delimited string to a stringlist annotation — missing_annotation_email","title":"Convert a delimited string to a stringlist annotation — missing_annotation_email","text":"Converts delimited string stringlist annotation adjust associated schema portal fileview.","code":""},{"path":"/reference/missing_annotation_email.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a delimited string to a stringlist annotation — missing_annotation_email","text":"","code":"missing_annotation_email(   fileview_id,   annotation_key,   created_date,   dry_run = TRUE )"},{"path":"/reference/missing_annotation_email.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a delimited string to a stringlist annotation — missing_annotation_email","text":"fileview_id synapse id fileview. Must desired annotations schema, must files annotate included scope. Must write access files want re-annotate. annotation_key character string annotation like use detect unannotated files. created_date date ('DD/MM/YYYY') cut dry_run Default = TRUE. Skips emailing instead prints summary tibble.","code":""},{"path":"/reference/missing_annotation_email.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a delimited string to a stringlist annotation — missing_annotation_email","text":"dry_run == T, returns study tibble skips upload.","code":""},{"path":"/reference/new_project.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new project — new_project","title":"Create a new project — new_project","text":"Set new NF project wiki, folders, fileview, permissions. parameters come project intake & data sharing plan (DSP) form. Aside default folders, folders tailored data mentioned DSP. NF-OSI team hard-coded admin addition funder team indicated funder. Since intended actual new projects, fail existing project detected.","code":""},{"path":"/reference/new_project.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new project — new_project","text":"","code":"new_project(   name,   pi,   lead,   admin_user = NULL,   abstract,   institution,   funder,   initiative,   datasets = NULL,   webview = FALSE,   ... )"},{"path":"/reference/new_project.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new project — new_project","text":"name Name project/study. pi Name principal investigator. lead Name(s) project lead/data coordinator, comma-sep multiple, e.g. \"Jane Doe, John Doe\". admin_user (Optional) Synapse username specified user made admin. Currently, takes one admin user, rest can added via UI. abstract Project abstract/description. institution Affiliated institution(s), semicolon-sep multiple, e.g. \"Stanford University; University California, San Francisco\". funder funding agency. relevant funder team made admin. initiative Title funding initiative, e.g. \"Young Investigator Award\". datasets (Optional) Datasets folders created main data folder (\"Raw Data\"). webview Whether open web browser view newly created project. Defaults FALSE. ... Additional arguments. used.","code":""},{"path":"/reference/new_project.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new project — new_project","text":"project object.","code":""},{"path":"/reference/new_project.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new project — new_project","text":"project created, NF Portal representation requires registration backend: New study row added Portal - Studies table. Project added Portal - Files scope.","code":""},{"path":"/reference/new_project_strict.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a strictly new project — new_project_strict","title":"Create a strictly new project — new_project_strict","text":"Internal handler creating project first checks whether project already exists disallows overwriting. less strict version allows overwriting warning, e.g. named update_project, implement createOrUpdate = TRUE compare createdOn modifiedOn issue warning (informative current Python client).","code":""},{"path":"/reference/new_project_strict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a strictly new project — new_project_strict","text":"","code":"new_project_strict(project_name)"},{"path":"/reference/new_project_strict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a strictly new project — new_project_strict","text":"project_name Name project created.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/ppp_mmd_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Pretty processing provenance mermaid template for the portal — ppp_mmd_template","title":"Pretty processing provenance mermaid template for the portal — ppp_mmd_template","text":"Mermaid flowchart helps navigate processed data interactive links default. See also https://github.com/mermaid-js/mermaid.","code":""},{"path":"/reference/ppp_mmd_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pretty processing provenance mermaid template for the portal — ppp_mmd_template","text":"","code":"ppp_mmd_template(   project_nodes,   input_dataset_nodes,   folder_nodes,   output_dataset_nodes,   workflow_links,   dataset_links,   clicks )"},{"path":"/reference/processing_flowchart.html","id":null,"dir":"Reference","previous_headings":"","what":"Wrapper to create data-driven flowchart with pretty processing provenance mermaid template — processing_flowchart","title":"Wrapper to create data-driven flowchart with pretty processing provenance mermaid template — processing_flowchart","text":"Wrapper create data-driven flowchart pretty processing provenance mermaid template","code":""},{"path":"/reference/processing_flowchart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Wrapper to create data-driven flowchart with pretty processing provenance mermaid template — processing_flowchart","text":"","code":"processing_flowchart(year = 1)"},{"path":"/reference/processing_flowchart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Wrapper to create data-driven flowchart with pretty processing provenance mermaid template — processing_flowchart","text":"year Year determine subset data generate flowchart.","code":""},{"path":"/reference/processing_flowchart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Wrapper to create data-driven flowchart with pretty processing provenance mermaid template — processing_flowchart","text":"","code":"if (FALSE) { flowchart <- processing_flowchart(year = 1) cat(flowchart, file = \"flowchart.mmd\") }"},{"path":"/reference/qc_manifest.html","id":null,"dir":"Reference","previous_headings":"","what":"QC a derived manifest — qc_manifest","title":"QC a derived manifest — qc_manifest","text":"Check missing annotations, usually input files missing values nothing copied. might also helpful visualize manifest via package like naniar::vis_miss(manifest).","code":""},{"path":"/reference/qc_manifest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"QC a derived manifest — qc_manifest","text":"","code":"qc_manifest(manifest, sample_io)"},{"path":"/reference/qc_manifest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"QC a derived manifest — qc_manifest","text":"manifest manifest, usually one annotate_* functions. sample_io Input/output mapping used; used missing annotations detected.","code":""},{"path":"/reference/qc_manifest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"QC a derived manifest — qc_manifest","text":"NULL problems, otherwise table entity ids affected, attributes missing, inputs used.","code":""},{"path":"/reference/register_study.html","id":null,"dir":"Reference","previous_headings":"","what":"Register a study in Portal - Studies — register_study","title":"Register a study in Portal - Studies — register_study","text":"Basically create row new NF-OSI project study Portal - Studies table","code":""},{"path":"/reference/register_study.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Register a study in Portal - Studies — register_study","text":"","code":"register_study(   name,   project_id,   abstract,   lead,   institution,   focus,   manifestation,   fileview_id,   funder = c(\"CTF\", \"GFF\", \"NTAP\"),   initiative,   study_status = \"Active\",   data_status = \"None\",   terms_access =     \"The data from this study is currently under embargo. Please contact the principal investigator for access to the data.\",   terms_acknowledgement =     \"The data from this study are still under embargo, therefore, if you have been granted access by the data contributor, you must work with them to determine how to acknowledge your collaboration in any manuscripts that arise. In addition, please acknowledge the NF Data Portal like so: \\\"The results published here are in whole or in part based on data obtained from the NF Data Portal (http://www.nf.synapse.org, RRID:SCR_021683) and made available through the NF Open Science Initiative.\\\"\",   grant_doi = \"\",   study_table_id = \"syn16787123\" )"},{"path":"/reference/register_study.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Register a study in Portal - Studies — register_study","text":"name Name project/study. project_id Synapse project id, used studyId. abstract Project abstract/description. lead Name(s) project lead/data coordinator, comma-sep multiple, e.g. \"Jane Doe, John Doe\". institution Affiliated institution(s), semicolon-sep multiple, e.g. \"Stanford University; University California, San Francisco\". focus NF focus, e.g. \"Neurofibromatosis type 1\". manifestation Character vector enum NF manifestation(s) associated study. fileview_id Synapse id study project's main fileview. funder funding agency. relevant funder team made admin. initiative Title funding initiative, e.g. \"Young Investigator Award\". study_status Status study, defaults \"Active\" new projects. data_status Status data, defaults \"None\" new projects. terms_access Access requirements blurb, uses default new projects. terms_acknowledgement Blurb study acknowledged materials reused. Unless specified PI/leads inception, leave blank new projects update later. grant_doi DOI grant proposal available. study_table_id Synapse id portal study table.","code":""},{"path":"/reference/register_study_files.html","id":null,"dir":"Reference","previous_headings":"","what":"Add new project scope to ","title":"Add new project scope to ","text":"Add new project scope \"Portal - Files\" fileview files project \"registered\" surfaced portal.","code":""},{"path":"/reference/register_study_files.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add new project scope to ","text":"","code":"register_study_files(project_id, portal_fileview = \"syn16858331\")"},{"path":"/reference/register_study_files.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add new project scope to ","text":"project_id project id, .e. container, added scope view. portal_fileview Synapse id \"Portal - Files\" entity view.","code":""},{"path":"/reference/remove_button.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove button from a project wiki — remove_button","title":"Remove button from a project wiki — remove_button","text":"provides way remove buttons longer present, possibly decided newer wiser design decisions. See also button_widget. target button selected based specified text label. reason multiple buttons label, removed.","code":""},{"path":"/reference/remove_button.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove button from a project wiki — remove_button","text":"","code":"remove_button(wiki, label, dry_run = TRUE)"},{"path":"/reference/remove_button.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove button from a project wiki — remove_button","text":"wiki wiki object operate . label Button label text. dry_run Whether return wiki object without actually performing update.","code":""},{"path":"/reference/remove_wiki_subpage.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove a subpage from a project wiki — remove_wiki_subpage","title":"Remove a subpage from a project wiki — remove_wiki_subpage","text":"Removes wiki subpage name (header). Currently, decline make mods exactly one match subpage. multiple subpages name, clear right one remove.","code":""},{"path":"/reference/remove_wiki_subpage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove a subpage from a project wiki — remove_wiki_subpage","text":"","code":"remove_wiki_subpage(project_id, subpage)"},{"path":"/reference/remove_wiki_subpage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove a subpage from a project wiki — remove_wiki_subpage","text":"project_id ID owner Synapse project. subpage Name subpage","code":""},{"path":"/reference/schema_max_str_len.html","id":null,"dir":"Reference","previous_headings":"","what":"Consult schema about max string length — schema_max_str_len","title":"Consult schema about max string length — schema_max_str_len","text":"Utility query schema regarding max string length key based current valid values. key values constrained (free-text), default string length 100 returned. schema, returns NA. : related fun consult schema type (integer, string, stringlist, etc.) : warn key actually string stringlist type","code":""},{"path":"/reference/schema_max_str_len.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Consult schema about max string length — schema_max_str_len","text":"","code":"schema_max_str_len(   key,   schema =     \"https://raw.githubusercontent.com/nf-osi/nf-metadata-dictionary/main/NF.jsonld\",   parent_context = \"bts\",   default = 100 )"},{"path":"/reference/schema_max_str_len.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Consult schema about max string length — schema_max_str_len","text":"key Schema key (label). schema URL local path .jsonld file schema read . parent_context Default = bts. JSON-LD context value question. default Default string length use keys without constrained values.","code":""},{"path":"/reference/strlist_JSON.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert delimited record to JSON representation needed by a stringlist col schema — strlist_JSON","title":"Convert delimited record to JSON representation needed by a stringlist col schema — strlist_JSON","text":"Internal helper reuses extends utility .delim_string_to_vector.","code":""},{"path":"/reference/strlist_JSON.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert delimited record to JSON representation needed by a stringlist col schema — strlist_JSON","text":"","code":"strlist_JSON(record, sep = \",\", trim_ws = T)"},{"path":"/reference/strlist_JSON.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert delimited record to JSON representation needed by a stringlist col schema — strlist_JSON","text":"record Character vector length one representing single record. sep Default = \",\". delimiter character string. trim_ws Default = TRUE. Remove white space beginning end list items (e.g. \"NF1, NF2\" \"NF1,NF2\" yield STRING_LIST result).","code":""},{"path":"/reference/summarize_file_access.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize file access for files within some view — summarize_file_access","title":"Summarize file access for files within some view — summarize_file_access","text":"portion adapted @allaway's original script. Common usages : Check numbers files viewable downloadable registered Synapse users: summarize_file_access(principal_id = 273948, access_type = \"DOWNLOAD\", \"syn16858331\") Check files within portal purview actually editable NF-OSI Sage Team, need least edit permissions updating annotations (historically, issues hackathon projects, etc.): summarize_file_access(principal_id = 3378999, access_type = \"UPDATE\", \"syn16858331\")","code":""},{"path":"/reference/summarize_file_access.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize file access for files within some view — summarize_file_access","text":"","code":"summarize_file_access(principal_id, access_type, fileview_id)"},{"path":"/reference/summarize_file_access.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize file access for files within some view — summarize_file_access","text":"principal_id Group(s) check access type. access_type access type(s) check ; result summarizes whether permissions types specified. fileview_id Syn id view. View must include benefactorId type.","code":""},{"path":"/reference/summarize_file_access.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize file access for files within some view — summarize_file_access","text":"complex usage: Check access multiple teams. summarizes file access using smaller set benefactors, returns data.table columns benefactorId, principalId, access, N, describes whether principalId specified access benefactorId N files. data can used aggregation needed.","code":""},{"path":"/reference/syn_login.html","id":null,"dir":"Reference","previous_headings":"","what":"Logs into Synapse. — syn_login","title":"Logs into Synapse. — syn_login","text":"Wrapper around https://python-docs.synapse.org/build/html/index.html#synapseclient.Synapse.login Similarly, providing args default highest preference using SYNAPSE_AUTH_TOKEN env var log .","code":""},{"path":"/reference/syn_login.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logs into Synapse. — syn_login","text":"","code":"syn_login(   username = NULL,   password = NULL,   authtoken = Sys.getenv(\"SYNAPSE_AUTH_TOKEN\") )"},{"path":"/reference/syn_login.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logs into Synapse. — syn_login","text":"username Synapse username (optional, required .synapseConfig available) password Synapse password (optional, required .synapseConfig available) authtoken Uses SYNAPSE_AUTH_TOKEN environmental variable, personal access token string can provided.","code":""},{"path":"/reference/syn_login.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Logs into Synapse. — syn_login","text":"","code":"if (FALSE) { library(nfportalutils) syn_login() }"},{"path":"/reference/syncBP_maf.html","id":null,"dir":"Reference","previous_headings":"","what":"Make cBioPortal mutations dataset from Synapse assets — syncBP_maf","title":"Make cBioPortal mutations dataset from Synapse assets — syncBP_maf","text":"NF-OSI workflow produces single merged maf file represents filtered subset mafs, containing (non-germline) data can released cBioPortal. However, data file immediately loadable instance cBioPortal server needs packaged files, example public mutations dataset. wrapper goes several steps needed create said bundle cBioPortal files conveniently.","code":""},{"path":"/reference/syncBP_maf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make cBioPortal mutations dataset from Synapse assets — syncBP_maf","text":"","code":"syncBP_maf(   merged_maf,   samplesheet,   ref_map,   ref_view,   name,   cancer_study_identifier,   citation = NULL,   pmid = NULL,   short_name = NULL,   publish_dir = cancer_study_identifier,   verbose = TRUE )"},{"path":"/reference/syncBP_maf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make cBioPortal mutations dataset from Synapse assets — syncBP_maf","text":"merged_maf Synapse id merged maf file public release. samplesheet Synapse id local path samplesheet release info. ref_map YAML file specifying mapping (NF) clinical metadata cBioPortal model. See details. ref_view view contains clinical data release files. name Name cancer study, e.g. something following convention \"Malignant Peripheral Nerve Sheath Tumor (NF-OSI, 2022)\". cancer_study_identifier Study identifier, convention {tumorType}_{institution}_{year}, example \"mpnst_nfosi_2022\". citation (Optional) relevant citation, e.g. \"TCGA, Nature 2012\". pmid (Optional) One relevant pubmed ids (comma separated without whitespace); used, citation NULL. short_name (Optional) Short name study. publish_dir output set files. Defaults (creating necessary) folder name cancer_study_identifier. verbose Whether provide informative messages throughout.","code":""},{"path":"/reference/syncBP_maf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make cBioPortal mutations dataset from Synapse assets — syncBP_maf","text":"simple sanity check version maf release file want, based samplesheet. example, version 1 samplesheet generate version 1 merged maf, later correction retracts sample (is_releasable=FALSE), step workflow generate merged maf rerun (), want make sure latest versions files used. latest versions samplesheets tied release currently stored syn38793855. (Note: Please file issue update doc changes.) Make clinical data files. NF, clinical metadata annotations files/surfaced view pretty basic. future, preferable store clinical metadata real normalized table. now, clinical data pulled view. map NF clinical variables cBioPortal dictionary recommended, step requires ref_map, YAML file. Make meta files. Meta files needed describing study, mutations data file, clinical data files.","code":""},{"path":"/reference/table_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic table query — table_query","title":"Generic table query — table_query","text":"Retrieve selected data Synapse table.","code":""},{"path":"/reference/table_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic table query — table_query","text":"","code":"table_query(table_id, columns = \"*\", includeRowIdAndRowVersion = F)"},{"path":"/reference/table_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic table query — table_query","text":"table_id Synapse table id. columns character vector selected columns (often correspond annotations, always). given, select columns. includeRowIdAndRowVersion Whether include row id etag, defaults FALSE. use case update rows table (rather just retrieve information viewing, use TRUE).","code":""},{"path":"/reference/table_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic table query — table_query","text":"tibble.","code":""},{"path":"/reference/test_failed.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a test fail message. — test_failed","title":"Format a test fail message. — test_failed","text":"Format test fail message.","code":""},{"path":"/reference/test_failed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a test fail message. — test_failed","text":"","code":"test_failed(display_string)"},{"path":"/reference/test_failed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a test fail message. — test_failed","text":"display_string character string format test failed message.","code":""},{"path":"/reference/test_failed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a test fail message. — test_failed","text":"message console","code":""},{"path":"/reference/test_passed.html","id":null,"dir":"Reference","previous_headings":"","what":"Format a test passed message. — test_passed","title":"Format a test passed message. — test_passed","text":"Format test passed message.","code":""},{"path":"/reference/test_passed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format a test passed message. — test_passed","text":"","code":"test_passed(display_string)"},{"path":"/reference/test_passed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format a test passed message. — test_passed","text":"display_string character string format test passed message.","code":""},{"path":"/reference/test_passed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format a test passed message. — test_passed","text":"message console","code":""},{"path":"/reference/update_study_annotations.html","id":null,"dir":"Reference","previous_headings":"","what":"Updates a set of files with project-level annotations. — update_study_annotations","title":"Updates a set of files with project-level annotations. — update_study_annotations","text":"Adds studyId, studyName, initiative, funder annotations set files fileview query. Assumes projectId==studyId. must Synapse default view column \"type\" present view. running function, changes may take minutes propagate Synapse.","code":""},{"path":"/reference/update_study_annotations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Updates a set of files with project-level annotations. — update_study_annotations","text":"","code":"update_study_annotations(study_table_id, fileview_id, annotations, dry_run = T)"},{"path":"/reference/update_study_annotations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Updates a set of files with project-level annotations. — update_study_annotations","text":"study_table_id synapse id portal study table. fileview_id synapse id fileview. Must desired annotations schema, must files annotate included scope. Must write access files want re-annotate. annotations vector annotations gather study table, assign files. dry_run Default = TRUE Skips upload annotations unless set FALSE.","code":""},{"path":"/reference/update_study_annotations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Updates a set of files with project-level annotations. — update_study_annotations","text":"dry_run == T, returns updated annotations tibble.","code":""},{"path":"/reference/update_study_annotations.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Updates a set of files with project-level annotations. — update_study_annotations","text":"","code":"if (FALSE) { update_study_annotations(study_table_id = \"syn16787123\",                          fileview_id = \"syn16858331\",                          annotations = c(\"studyId\",\"studyName\",\"initiative\",\"fundingAgency\"),                          dry_run = T) }"},{"path":"/reference/use_ref_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Read and use a mapping file — use_ref_map","title":"Read and use a mapping file — use_ref_map","text":"mapping file YAML JSON format file minimally mapping key storing translations source data model element target data model. See example file NF. util reads mapping file, light checking, creates list object downstream functions can use.","code":""},{"path":"/reference/use_ref_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read and use a mapping file — use_ref_map","text":"","code":"use_ref_map(ref_map, as_dt = TRUE)"},{"path":"/reference/use_ref_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read and use a mapping file — use_ref_map","text":"ref_map YAML JSON mapping. See details. as_dt Return data.table, default, otherwise checking just return list representation, retains metadata.","code":""},{"path":"/reference/use_ref_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read and use a mapping file — use_ref_map","text":"Either list lists storing source, label, description, data_type, attribute_type data.table representation.","code":""},{"path":"/reference/use_ref_map.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Read and use a mapping file — use_ref_map","text":"specification mapping file later formalized different structure handled accordingly (say, one --hood things can change).","code":""},{"path":"/reference/walk.html","id":null,"dir":"Reference","previous_headings":"","what":"Walk through a directory — walk","title":"Walk through a directory — walk","text":"now, internal util imported synapseutils.","code":""},{"path":"/reference/walk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Walk through a directory — walk","text":"","code":"walk(syn_id, as_list = TRUE)"},{"path":"/reference/walk.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Walk through a directory — walk","text":"syn_id Synapse id directory root traverse. as_list","code":""},{"path":"/reference/walk.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Walk through a directory — walk","text":"R list Py generator object.","code":""},{"path":"/reference/wiki_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Add markup to a project wiki — wiki_mod","title":"Add markup to a project wiki — wiki_mod","text":"Add markup existing project wiki, e.g. regular markdown, widget, Synapse wiki compatible content. Errors encountered one tries modify project wiki exist.","code":""},{"path":"/reference/wiki_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add markup to a project wiki — wiki_mod","text":"","code":"wiki_mod(   content,   project_id,   subpage = NULL,   where = c(\"top\", \"bottom\"),   dry_run = TRUE )"},{"path":"/reference/wiki_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add markup to a project wiki — wiki_mod","text":"content Markdown markup compatible Synapse wikis. project_id ID owner Synapse project. subpage given character name, add new subpage name. NULL, contents added main page. add markup page, \"top\" \"bottom\" (defaults \"top\"). used adding main page, may already content. dry_run Whether return wiki object without actually performing update.","code":""},{"path":"/reference/write_cbio_clinical.html","id":null,"dir":"Reference","previous_headings":"","what":"Write cBioPortal clinical file — write_cbio_clinical","title":"Write cBioPortal clinical file — write_cbio_clinical","text":"Wrapper function creating clinical files. two: PATIENT SAMPLE. PATIENT file actually optional, checks making sure SAMPLE can created. df expected table containing clinical data available, maybe even irrelevant data (since NF data well-normalized single table everything).","code":""},{"path":"/reference/write_cbio_clinical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write cBioPortal clinical file — write_cbio_clinical","text":"","code":"write_cbio_clinical(   df,   ref_map,   na_recode = c(\"NA\", \"NaN\", \"unknown\", \"Unknown\"),   delim = \"\\t\",   publish_dir = \".\",   verbose = TRUE )"},{"path":"/reference/write_cbio_clinical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write cBioPortal clinical file — write_cbio_clinical","text":"df data.frame representing clinical dataset publicize. ref_map YAML JSON mapping. See details. na_recode Possible NA values replace blank string (seems standard) exported file. delim Delimiter character used writing file, defaults tab-delimited per cBioPortal specs. publish_dir Directory path write , defaults current. verbose Report file written.","code":""},{"path":"/reference/write_cbio_clinical.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Write cBioPortal clinical file — write_cbio_clinical","text":"relies ref_map specification know clinical data include cBioPortal segregate clinical attributes right files. example, say df contains clinical variables -X, mappings specified variables -C, L-M others meant surfaced/made public. subset df specified mapping. Conversely, mapping variable Z clinical data, throw error.","code":""},{"path":"/reference/write_meta.html","id":null,"dir":"Reference","previous_headings":"","what":"Write meta file — write_meta","title":"Write meta file — write_meta","text":"Slightly different implementation https://github.com/Sage-Bionetworks/genie-erbb2-cbio/blob/develop/create_meta.R#L220","code":""},{"path":"/reference/write_meta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write meta file — write_meta","text":"","code":"write_meta(data, filename, publish_dir = \".\", verbose = TRUE)"},{"path":"/reference/write_meta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write meta file — write_meta","text":"data data (lines) write. filename Name file. publish_dir Directory path write , defaults current. verbose Report file written.","code":""}]
